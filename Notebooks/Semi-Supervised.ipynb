{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPS5KFZ1nLDD",
        "outputId": "398c3c0c-f9fd-48c3-e215-abe6580f702d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    print(\"Loading images from folder:\", folder)\n",
        "    for label in os.listdir(folder):\n",
        "        label_folder = os.path.join(folder, label)\n",
        "        if os.path.isdir(label_folder):  # Check if it's a directory\n",
        "            for filename in os.listdir(label_folder):\n",
        "                img = image.load_img(os.path.join(label_folder, filename), target_size=(224, 224))\n",
        "                img = image.img_to_array(img)\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "        else:\n",
        "            # If it's not a directory, assume all images are directly in the unlabeled folder\n",
        "            img = image.load_img(os.path.join(folder, label), target_size=(224, 224))\n",
        "            img = image.img_to_array(img)\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load labeled data\n",
        "labeled_folder = '/content/drive/My Drive/dataset4/labeled'\n",
        "X_labeled, y_labeled = load_images_from_folder(labeled_folder)\n",
        "\n",
        "# Load unlabeled data\n",
        "unlabeled_folder = '/content/drive/My Drive/dataset4/unlabeled'\n",
        "X_unlabeled, _ = load_images_from_folder(unlabeled_folder)\n",
        "\n",
        "# Split labeled data into training and testing sets\n",
        "X_train_labeled, X_test, y_train_labeled, y_test = train_test_split(X_labeled, y_labeled, test_size=0.2, random_state=42)\n",
        "print(X_unlabeled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxOyPuIqnVmm",
        "outputId": "edfbc6d1-bb5f-4339-ef2d-70834ce01f85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images from folder: /content/drive/My Drive/dataset4/labeled\n",
            "Loading images from folder: /content/drive/My Drive/dataset4/unlabeled\n",
            "[[[[119. 154. 208.]\n",
            "   [118. 155. 208.]\n",
            "   [115. 155. 207.]\n",
            "   ...\n",
            "   [200. 191. 218.]\n",
            "   [193. 186. 219.]\n",
            "   [176. 170. 206.]]\n",
            "\n",
            "  [[120. 155. 209.]\n",
            "   [119. 156. 209.]\n",
            "   [116. 156. 208.]\n",
            "   ...\n",
            "   [169. 180. 208.]\n",
            "   [159. 172. 206.]\n",
            "   [151. 164. 199.]]\n",
            "\n",
            "  [[121. 157. 209.]\n",
            "   [120. 157. 209.]\n",
            "   [117. 157. 208.]\n",
            "   ...\n",
            "   [138. 167. 201.]\n",
            "   [131. 161. 199.]\n",
            "   [133. 162. 202.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[105.  89.  76.]\n",
            "   [118. 100.  78.]\n",
            "   [100.  80.  56.]\n",
            "   ...\n",
            "   [ 72.  59.  43.]\n",
            "   [ 85.  72.  56.]\n",
            "   [ 96.  83.  67.]]\n",
            "\n",
            "  [[ 96.  78.  66.]\n",
            "   [110.  93.  73.]\n",
            "   [ 76.  58.  36.]\n",
            "   ...\n",
            "   [ 80.  66.  53.]\n",
            "   [ 85.  71.  60.]\n",
            "   [ 65.  51.  40.]]\n",
            "\n",
            "  [[110.  92.  80.]\n",
            "   [ 99.  84.  65.]\n",
            "   [104.  86.  66.]\n",
            "   ...\n",
            "   [ 59.  45.  36.]\n",
            "   [ 62.  48.  39.]\n",
            "   [ 62.  48.  39.]]]\n",
            "\n",
            "\n",
            " [[[140. 166. 215.]\n",
            "   [140. 166. 215.]\n",
            "   [140. 166. 215.]\n",
            "   ...\n",
            "   [175. 186. 204.]\n",
            "   [175. 186. 204.]\n",
            "   [175. 186. 204.]]\n",
            "\n",
            "  [[141. 168. 215.]\n",
            "   [141. 168. 215.]\n",
            "   [141. 168. 215.]\n",
            "   ...\n",
            "   [176. 187. 205.]\n",
            "   [176. 187. 205.]\n",
            "   [175. 186. 204.]]\n",
            "\n",
            "  [[142. 169. 216.]\n",
            "   [142. 169. 216.]\n",
            "   [142. 169. 216.]\n",
            "   ...\n",
            "   [177. 188. 206.]\n",
            "   [177. 188. 206.]\n",
            "   [175. 186. 204.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[137. 136. 142.]\n",
            "   [137. 136. 142.]\n",
            "   [138. 137. 143.]\n",
            "   ...\n",
            "   [147. 146. 151.]\n",
            "   [148. 147. 152.]\n",
            "   [145. 144. 149.]]\n",
            "\n",
            "  [[137. 136. 142.]\n",
            "   [138. 137. 143.]\n",
            "   [140. 139. 145.]\n",
            "   ...\n",
            "   [147. 146. 151.]\n",
            "   [145. 144. 149.]\n",
            "   [148. 147. 152.]]\n",
            "\n",
            "  [[137. 136. 142.]\n",
            "   [139. 138. 144.]\n",
            "   [141. 140. 146.]\n",
            "   ...\n",
            "   [135. 134. 139.]\n",
            "   [144. 143. 148.]\n",
            "   [146. 145. 150.]]]\n",
            "\n",
            "\n",
            " [[[197. 204. 196.]\n",
            "   [199. 205. 191.]\n",
            "   [194. 201. 183.]\n",
            "   ...\n",
            "   [ 19.  19.  17.]\n",
            "   [ 31.  32.  27.]\n",
            "   [ 31.  32.  26.]]\n",
            "\n",
            "  [[136. 143. 136.]\n",
            "   [136. 142. 132.]\n",
            "   [132. 138. 126.]\n",
            "   ...\n",
            "   [ 24.  27.  32.]\n",
            "   [ 16.  17.  22.]\n",
            "   [ 19.  19.  21.]]\n",
            "\n",
            "  [[ 48.  53.  49.]\n",
            "   [ 49.  54.  50.]\n",
            "   [ 50.  55.  51.]\n",
            "   ...\n",
            "   [ 11.  18.  34.]\n",
            "   [  8.  11.  26.]\n",
            "   [ 13.  12.  26.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 74.  66.  45.]\n",
            "   [ 73.  67.  43.]\n",
            "   [ 60.  56.  29.]\n",
            "   ...\n",
            "   [151. 157.  59.]\n",
            "   [151. 158.  46.]\n",
            "   [151. 154.  73.]]\n",
            "\n",
            "  [[ 69.  61.  42.]\n",
            "   [ 79.  75.  50.]\n",
            "   [ 64.  60.  35.]\n",
            "   ...\n",
            "   [152. 162.  11.]\n",
            "   [155. 162.   4.]\n",
            "   [156. 162.  30.]]\n",
            "\n",
            "  [[ 55.  47.  28.]\n",
            "   [ 62.  58.  33.]\n",
            "   [ 64.  58.  34.]\n",
            "   ...\n",
            "   [159. 160.   0.]\n",
            "   [162. 160.   0.]\n",
            "   [162. 157.  14.]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 46.  65.  80.]\n",
            "   [ 60.  79.  93.]\n",
            "   [ 49.  69.  80.]\n",
            "   ...\n",
            "   [ 41.  61.  70.]\n",
            "   [ 72.  95. 111.]\n",
            "   [ 24.  45.  72.]]\n",
            "\n",
            "  [[ 51.  70.  85.]\n",
            "   [ 45.  64.  78.]\n",
            "   [ 57.  77.  88.]\n",
            "   ...\n",
            "   [ 90. 109. 123.]\n",
            "   [ 25.  47.  61.]\n",
            "   [ 23.  45.  68.]]\n",
            "\n",
            "  [[ 56.  75.  92.]\n",
            "   [ 50.  69.  84.]\n",
            "   [ 58.  77.  91.]\n",
            "   ...\n",
            "   [ 40.  58.  72.]\n",
            "   [ 64.  84.  93.]\n",
            "   [ 41.  62.  79.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[137. 163.  74.]\n",
            "   [133. 159.  70.]\n",
            "   [119. 145.  56.]\n",
            "   ...\n",
            "   [ 97. 116.  27.]\n",
            "   [127. 141.  56.]\n",
            "   [101. 113.  29.]]\n",
            "\n",
            "  [[ 99. 128.  38.]\n",
            "   [131. 160.  70.]\n",
            "   [107. 136.  46.]\n",
            "   ...\n",
            "   [ 76.  95.   6.]\n",
            "   [135. 149.  64.]\n",
            "   [109. 121.  37.]]\n",
            "\n",
            "  [[103. 136.  45.]\n",
            "   [135. 168.  77.]\n",
            "   [130. 163.  72.]\n",
            "   ...\n",
            "   [ 90. 110.  21.]\n",
            "   [136. 150.  65.]\n",
            "   [117. 131.  46.]]]\n",
            "\n",
            "\n",
            " [[[ 72. 117. 174.]\n",
            "   [ 72. 117. 174.]\n",
            "   [ 73. 118. 175.]\n",
            "   ...\n",
            "   [ 68. 110. 168.]\n",
            "   [ 66. 108. 166.]\n",
            "   [ 66. 108. 166.]]\n",
            "\n",
            "  [[ 73. 118. 175.]\n",
            "   [ 73. 118. 175.]\n",
            "   [ 74. 119. 176.]\n",
            "   ...\n",
            "   [ 68. 110. 168.]\n",
            "   [ 67. 109. 167.]\n",
            "   [ 67. 109. 167.]]\n",
            "\n",
            "  [[ 74. 119. 176.]\n",
            "   [ 74. 119. 176.]\n",
            "   [ 75. 120. 177.]\n",
            "   ...\n",
            "   [ 68. 110. 168.]\n",
            "   [ 68. 110. 168.]\n",
            "   [ 68. 110. 168.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[119. 103.  87.]\n",
            "   [126. 110.  94.]\n",
            "   [113.  97.  81.]\n",
            "   ...\n",
            "   [100.  87.  71.]\n",
            "   [102.  89.  73.]\n",
            "   [107.  94.  78.]]\n",
            "\n",
            "  [[114.  98.  82.]\n",
            "   [121. 105.  89.]\n",
            "   [119. 103.  87.]\n",
            "   ...\n",
            "   [ 98.  85.  69.]\n",
            "   [104.  91.  75.]\n",
            "   [ 97.  84.  68.]]\n",
            "\n",
            "  [[124. 108.  92.]\n",
            "   [118. 102.  86.]\n",
            "   [125. 109.  93.]\n",
            "   ...\n",
            "   [102.  89.  73.]\n",
            "   [105.  92.  76.]\n",
            "   [ 99.  86.  70.]]]\n",
            "\n",
            "\n",
            " [[[185. 193. 196.]\n",
            "   [189. 194. 197.]\n",
            "   [190. 194. 195.]\n",
            "   ...\n",
            "   [205. 206. 200.]\n",
            "   [206. 207. 201.]\n",
            "   [206. 207. 201.]]\n",
            "\n",
            "  [[185. 193. 196.]\n",
            "   [189. 194. 197.]\n",
            "   [190. 194. 195.]\n",
            "   ...\n",
            "   [204. 205. 200.]\n",
            "   [204. 205. 200.]\n",
            "   [204. 205. 200.]]\n",
            "\n",
            "  [[185. 193. 196.]\n",
            "   [189. 194. 197.]\n",
            "   [190. 194. 195.]\n",
            "   ...\n",
            "   [203. 204. 199.]\n",
            "   [203. 204. 199.]\n",
            "   [203. 204. 199.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 14.  13.  11.]\n",
            "   [ 13.  12.  10.]\n",
            "   [ 14.  13.  11.]\n",
            "   ...\n",
            "   [218. 209. 200.]\n",
            "   [227. 207. 180.]\n",
            "   [183. 149.  59.]]\n",
            "\n",
            "  [[ 13.  12.  10.]\n",
            "   [ 13.  12.  10.]\n",
            "   [ 14.  13.  11.]\n",
            "   ...\n",
            "   [221. 208. 192.]\n",
            "   [223. 205. 193.]\n",
            "   [231. 210. 155.]]\n",
            "\n",
            "  [[ 12.  11.   9.]\n",
            "   [ 14.  13.  11.]\n",
            "   [ 14.  13.  11.]\n",
            "   ...\n",
            "   [222. 206. 181.]\n",
            "   [217. 200. 193.]\n",
            "   [215. 204. 174.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "tree_model = DecisionTreeClassifier()\n",
        "\n",
        "# Flatten image arrays\n",
        "X_train_labeled_flatten = X_train_labeled.reshape(X_train_labeled.shape[0], -1)\n",
        "\n",
        "# Train initial model on labeled data\n",
        "tree_model.fit(X_train_labeled_flatten, y_train_labeled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "8KHoUg2zsSZF",
        "outputId": "7c3ac3d4-7b48-4314-940e-8488b94d0498"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict labels for unlabeled data\n",
        "pseudo_labels = tree_model.predict(X_unlabeled.reshape(X_unlabeled.shape[0], -1))\n",
        "\n",
        "# Select most confident predictions\n",
        "confidence_threshold = 0.9\n",
        "confidence_scores = tree_model.predict_proba(X_unlabeled.reshape(X_unlabeled.shape[0], -1)).max(axis=1)\n",
        "confident_predictions = confidence_scores > confidence_threshold\n",
        "\n",
        "X_confident = X_unlabeled[confident_predictions]\n",
        "pseudo_labels_confident = pseudo_labels[confident_predictions]\n",
        "\n",
        "# Add confident predictions to labeled data\n",
        "X_train_labeled = np.concatenate([X_train_labeled, X_confident])\n",
        "y_train_labeled = np.concatenate([y_train_labeled, pseudo_labels_confident])\n"
      ],
      "metadata": {
        "id": "Q_cBu-A5savj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RmNa0iLg4ARI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten expanded labeled data\n",
        "X_train_labeled_flatten = X_train_labeled.reshape(X_train_labeled.shape[0], -1)\n",
        "\n",
        "# Retrain model with expanded labeled data\n",
        "tree_model.fit(X_train_labeled_flatten, y_train_labeled)\n",
        "\n",
        "# Predict labels for test set\n",
        "y_pred = tree_model.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print(\"Accuracy of the semi-supervised model:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijrZ_Vv_u8I_",
        "outputId": "f4f6275b-a9af-41a2-9293-2bc8cd1c2504"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the semi-supervised model: 0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "tree_model = DecisionTreeClassifier()\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=tree_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train_labeled_flatten, y_train_labeled)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "\n",
        "# Retrain the model with the best hyperparameters\n",
        "tree_model_best = DecisionTreeClassifier(**best_params)\n",
        "tree_model_best.fit(X_train_labeled_flatten, y_train_labeled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "67b9dee3-8ce9-44e6-fcec-e74affd80842",
        "id": "EqOVBZxC4BbO"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DecisionTreeClassifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1342f98dc404>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Initialize Decision Tree classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtree_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Perform grid search with cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
          ]
        }
      ]
    }
  ]
}