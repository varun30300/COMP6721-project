{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8375af-9c08-4029-a087-4be3fcfb587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c85d1374-f5ef-4f4a-bbaf-49cf92bced7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_filters, kernel_size, dropout_rate, num_units1, num_units2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, num_filters, kernel_size=kernel_size, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Assuming input size is (3, 64, 64)\n",
    "        self.input_size = 64\n",
    "        self.conv_output_size = self._get_conv_output_size(self.input_size, kernel_size, 2)  # 2 is the pool size\n",
    "\n",
    "        self.fc1 = nn.Linear(num_filters * self.conv_output_size * self.conv_output_size, num_units1)\n",
    "        self.fc2 = nn.Linear(num_units1, num_units2)\n",
    "        self.fc3 = nn.Linear(num_units2, 5)  # 5 classes for airfield, bus stand, canyon, market, temple\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "    def _get_conv_output_size(self, input_size, kernel_size, pool_size):\n",
    "        # Calculate output size after a single conv + pool layer\n",
    "        # Output size after convolution\n",
    "        conv_output_size = (input_size - (kernel_size - 1) - 1 + 2) // 1 + 1\n",
    "        # Output size after pooling\n",
    "        conv_output_size = (conv_output_size - (pool_size - 1) - 1) // pool_size + 1\n",
    "        return conv_output_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa152eda-727b-48c1-924a-e7e6d72788fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root_dir, batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(root=f'{root_dir}/train', transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(root=f'{root_dir}/test', transform=transform)\n",
    "    validation_dataset = datasets.ImageFolder(root=f'{root_dir}/validation', transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    class_names = train_dataset.classes\n",
    "\n",
    "    return train_loader, test_loader, validation_loader, class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2ef34d-9769-4354-b155-3e176d625bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc='Evaluating', leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba3d4d72-73fe-46ff-ac7f-65aceb50aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c481ece4-3e39-4a56-8bdd-ef2ba4950ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names, save_path):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa88f5c2-6952-42c9-a072-920cd26c3e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7650\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "saved_model_path = 'best_model_20240615_101908.pth'\n",
    "num_filters = 32  # or the value used in your best model\n",
    "kernel_size = 5  # or the value used in your best model\n",
    "dropout_rate = 0.0  # or the value used in your best model\n",
    "num_units1 = 64  # or the value used in your best model\n",
    "num_units2 = 32  # or the value used in your best model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN(num_filters, kernel_size, dropout_rate, num_units1, num_units2).to(device)\n",
    "model.load_state_dict(torch.load(saved_model_path, map_location=device))\n",
    "\n",
    "# Load data\n",
    "root_dir = \"D:\\Study\\COMP 6721\\COMP6721-project\\Dataset\"\n",
    "batch_size = 32  # or the value used in your best model\n",
    "train_loader, test_loader, validation_loader, class_names = load_data(root_dir, batch_size)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_accuracy = evaluate_model(model, test_loader, device)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Get predictions and plot confusion matrix\n",
    "test_preds, test_labels = get_predictions(model, test_loader, device)\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "plot_confusion_matrix(cm, class_names, 'confusion_matrix2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab27066-48a6-493c-9731-5b77517d2e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=30752, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d8257-446b-4a9b-ac86-6315c69caccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
